{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from model import unet, deeplabv3plus, deeplabv3plus_mobilev2, hrnet\n",
    "from utils.metrics import oa_binary, miou_binary\n",
    "from dataloader.preprocess import read_normalize\n",
    "from dataloader.loader import patch_tensor_dset, scene_dset\n",
    "from dataloader.parallel_loader import threads_scene_dset\n",
    "from utils.plot_dset_one import plot_dset_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 200\n",
    "model_name_save = 'unet_trained_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "torch.manual_seed(999)            #### make the trianing replicable\n",
    "model = unet(num_bands=6, num_classes=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data paths \n",
    "### The whole dataset.\n",
    "paths_scene = sorted(glob(config.dir_s2 + '/scene/*'))\n",
    "paths_truth = [path_scene.replace('/scene/', '/truth/').replace('_6Bands', '').split('.')[0] + '_truth.tif' for path_scene in paths_scene]\n",
    "### Select training part from the dataset.\n",
    "id_scene = [i for i in range(len(paths_scene))]\n",
    "id_tra_scene = list(set(id_scene) - set(config.i_valset))\n",
    "paths_tra_scene, paths_tra_truth = [paths_scene[i] for i in id_tra_scene], [paths_truth[i] for i in id_tra_scene]\n",
    "len(paths_tra_scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation part of the dataset (patch format)\n",
    "paths_patch_val = sorted(glob(config.dir_patch_val_s2+'/*'))   ## Validation patches\n",
    "'''--------- 1. Data loading --------'''\n",
    "'''----- 1.1 training data loading (from scenes path) '''\n",
    "tra_scenes, tra_truths = read_normalize(paths_img=paths_tra_scene, \\\n",
    "                            paths_truth=paths_tra_truth, max_bands=config.bands_max, min_bands=config.bands_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data:   75\n",
      "time comsuming:   0.00028705596923828125\n"
     ]
    }
   ],
   "source": [
    "''' ----- 1.2. Training data loading and auto augmentation'''\n",
    "time_start = time.time()\n",
    "# tra_dset = threads_scene_dset(scene_list = tra_scenes, \\\n",
    "#                               truth_list = tra_truths, \n",
    "#                               transforms=config.transforms_tra, \n",
    "#                               num_thread=1)          ###  num_thread(30) patches per scene.\n",
    "\n",
    "tra_dset = scene_dset(scene_list = tra_scenes, \n",
    "                             truth_list = tra_truths,\n",
    "                             transforms = config.transforms_tra, \n",
    "                             patch_size = [256, 256])\n",
    "print('size of training data:  ', len(tra_dset))\n",
    "print('time comsuming:  ', time.time()-time_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of validation data: 1000\n"
     ]
    }
   ],
   "source": [
    "''' ----- 1.3. validation data loading (validation patches) ------ '''\n",
    "patch_list_val = [torch.load(path) for path in paths_patch_val]\n",
    "val_dset = patch_tensor_dset(patch_pair_list = patch_list_val)\n",
    "print('size of validation data:', val_dset.__len__())\n",
    "tra_loader = torch.utils.data.DataLoader(tra_dset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------train step------'''\n",
    "def train_step(model, loss_fn, optimizer, x, y):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    miou = miou_binary(pred=pred, truth=y)\n",
    "    oa = oa_binary(pred=pred, truth=y)\n",
    "    return loss, miou, oa\n",
    "\n",
    "'''------validation step------'''\n",
    "def val_step(model, loss_fn, x, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "    miou = miou_binary(pred=pred, truth=y)\n",
    "    oa = oa_binary(pred=pred, truth=y)\n",
    "    return loss, miou, oa\n",
    "\n",
    "'''------ train loops ------'''\n",
    "def train_loops(model, loss_fn, optimizer, tra_loader, val_loader, epoches, lr_scheduler=None):\n",
    "    size_tra_loader = len(tra_loader)\n",
    "    size_val_loader = len(val_loader)\n",
    "    tra_loss_loops, tra_miou_loops = [], []\n",
    "    val_loss_loops, val_miou_loops = [], []\n",
    "    for epoch in range(epoches):\n",
    "        start = time.time()\n",
    "        tra_loss, val_loss = 0, 0\n",
    "        tra_miou, val_miou = 0, 0\n",
    "        tra_oa, val_oa = 0, 0\n",
    "\n",
    "        '''----- 1. train the model -----'''\n",
    "        for x_batch, y_batch in tra_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_batch = config.label_smooth(y_batch) \n",
    "            loss, miou, oa = train_step(model=model, loss_fn=loss_fn, \\\n",
    "                                            optimizer=optimizer, x=x_batch, y=y_batch)\n",
    "            tra_loss += loss.item()\n",
    "            tra_miou += miou.item()\n",
    "            tra_oa += oa.item()\n",
    "        if lr_scheduler:\n",
    "          lr_scheduler.step(tra_loss)         # using learning rate scheduler\n",
    "\n",
    "        '''----- 2. validate the model -----'''\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch, y_batch = x_batch.to(device).to(dtype=torch.float32), y_batch.to(device)    \n",
    "            loss, miou, oa = val_step(model=model, loss_fn=loss_fn, x=x_batch, y=y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_miou += miou.item()\n",
    "            val_oa += oa.item()\n",
    "\n",
    "        '''------ 3. print mean accuracy ------'''\n",
    "        tra_loss = tra_loss/size_tra_loader\n",
    "        val_loss = val_loss/size_val_loader\n",
    "        tra_miou = tra_miou/size_tra_loader\n",
    "        val_miou = val_miou/size_val_loader\n",
    "        tra_oa = tra_oa/size_tra_loader\n",
    "        val_oa = val_oa/size_val_loader\n",
    "        tra_loss_loops.append(tra_loss), tra_miou_loops.append(tra_miou)\n",
    "        val_loss_loops.append(val_loss), val_miou_loops.append(val_miou)\n",
    "        format = 'Ep{}: Tra-> Loss:{:.3f}, Oa:{:.3f}, Miou:{:.3f}, Val-> Loss:{:.3f}, Oa:{:.3f}, Miou:{:.3f}, Time:{:.1f}s'\n",
    "        print(format.format(epoch+1, tra_loss, tra_oa, tra_miou, val_loss, val_oa, val_miou, time.time()-start))\n",
    "    metrics = {'tra_loss':tra_loss_loops, 'tra_miou':tra_miou_loops, 'val_loss': val_loss_loops, 'val_miou': val_miou_loops}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep1: Tra-> Loss:0.366, Oa:0.959, Miou:0.913, Val-> Loss:0.157, Oa:0.966, Miou:0.934, Time:3.0s\n"
     ]
    }
   ],
   "source": [
    "''' -------- 2. Model loading and training strategy ------- '''\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6, patience=20)\n",
    "\n",
    "''' -------- 3. Model training for loops ------- '''\n",
    "metrics = train_loops(model=model,  \n",
    "                    loss_fn=config.loss_bce, \n",
    "                    optimizer=optimizer,  \n",
    "                    tra_loader=tra_loader,  \n",
    "                    val_loader=val_loader,  \n",
    "                    epoches=200,  \n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights are saved to -->  model/trained_model/unet_trained_1_weights.pth\n",
      "Training metrics are saved to -->  model/trained_model/unet_trained_1_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "''' -------- 4. trained model and accuracy metric saving  ------- '''\n",
    "# model saving\n",
    "path_weights = 'model/trained_model/' + model_name_save + '_weights.pth'\n",
    "torch.save(model.state_dict(), path_weights)\n",
    "print('Model weights are saved to --> ', path_weights)\n",
    "## metrics saving\n",
    "path_metrics = 'model/trained_model/' + model_name_save + '_metrics.csv'\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.to_csv(path_metrics, index=False, sep=',')\n",
    "metrics_df = pd.read_csv(path_metrics)\n",
    "print('Training metrics are saved to --> ', path_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-watnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
